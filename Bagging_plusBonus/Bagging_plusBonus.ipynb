{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4 - Bagging and Hyperparameter tuning  \n",
    "\n",
    "<img src=\"./images/bags.jpg\" alt=\"The bagging operation\" width=\"400\" align='center'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Spam vs. not-Spam Dataset\n",
    "<img src=\"./images/spam_or_not_spam.png\" alt=\"Spam vs. not-Spam\" width=\"300\" align='center'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the (Spam vs. not-Spam) dataset:\n",
    "* The dataset tags email messages as spam or not-spam.\n",
    "* Classes (=categories): there are two possible classes: not_spam, spam\n",
    "* Attributes (=features): there are 57 features, including two types of features:\n",
    "  * word frequencies - the feature name contains a word, with the suffix '_wordFreq' e.g.: 'make_wordFreq'  \n",
    "    * The word could appear 0 times in a specific email, once or a few times.\n",
    "    * The values of this feature could be between 0 and 1 (the frequency is relative).\n",
    "  * Capital Letter pattern attributes - 3 features regarding capital letter patterns. e.g.: 'capitalLet_long' - the length of the longest sequence of capital letters in the email."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The assignment has to do with the (Spam vs. not-Spam) dataset\n",
    "* This assignment is a bigger assignment and is graded accordingly (20 points total)\n",
    "  * It includes different methods to implement, related to the Bagging algorithm \n",
    "* At the end of the assignment, there is an optional bonus method to implement (additional 5 points)\n",
    "  * It also includes an , regarding hyperparameters tunig \n",
    "* Note: the maximum possible points for all the assignments together are - 70 points \n",
    "  * The extra 30 points come from the test\n",
    "* Note: previous assignments and class exercises, could assist you with similar materials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General instructions:\n",
    "Please Read the following instructions, and make sure you follow all steps, before submiting your assignment via moodle:\n",
    "- Put your code one line after the '# YOUR CODE HERE' remark\n",
    "- You must remove the 'raise NotImplementedError()' exception raising line (which appears a line after the above remark).\n",
    "    * if you do not remove this line, it will be a sign that you didn't implement that code, and we won't be able to check your work\n",
    "- Do NOT remove any other line in this notebook    \n",
    "- you also need to implement the two functions 'myName', 'myId'\n",
    "    * myName - you need to return your full name as a string\n",
    "    * myId - you need to return your ID number as a an integer    \n",
    "- When you want to check your work, select the 'Cell' --> 'Run All' menu\n",
    "    * before performing your filnal test, we suggest to clear previous output (by selecting 'Cell' --> 'All output' --> 'Clear' menu) and then reperform the final execution ('Cell' --> 'Run All') of the code.\n",
    "    * after performing 'Run All', make sure there are no exceptions thrown and that the output is as you expected.\n",
    "- Don't forget to save your work, by clicking the 'save' icon (in the upper left part of the screen), or by selecting the 'File' --> 'Save and checkpoint' menu item. \n",
    "- Do NOT change the file name of this notebook\n",
    "- The work is done individualy, for each student\n",
    "- Each student needs to submit his/her assignment through moodle.\n",
    "- Submit the python notebook only (not any additional possible files) \n",
    "<br/><br/>\n",
    "Good Luck :-)<br/>\n",
    "The courses staff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 - Student information methods:\n",
    "The following 2 cells consist of 2 methods which aim to validate your details.<br/>\n",
    "Please <b>make sure to implement <u>both</u> of them</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a9b37d2297534714fc0f385d860f6b2f",
     "grade": false,
     "grade_id": "myName-Method",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: \n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# The following is expected:\n",
    "# --- the method needs to return your full name (as a string)\n",
    "# example: assume your name is John Smith:\n",
    "# return 'John Smith'\n",
    "# ------------\n",
    "# return value:\n",
    "# - your full name (as a string)\n",
    "# ---------------------\n",
    "# --- General notes:\n",
    "# Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "# In the line following the '# YOUR CODE HERE' line, add your code\n",
    "# ---------------------\n",
    "def myName():\n",
    "    # ADD the return statement in the LINE AFTER: '# YOUR CODE HERE'\n",
    "    # REMOVE THE LINE: raise NotImplementedError()\n",
    "    # YOUR CODE HERE\n",
    "    return \"Menahem Ovrutski\"\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf205f4550ee70f47db218c42b267bc7",
     "grade": false,
     "grade_id": "myIdMethod",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: \n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# The following is expected:\n",
    "# --- the method needs to return your ID number (as an integer number)\n",
    "# example: assume your ID number is 1234:\n",
    "# return 1234 \n",
    "# ------------\n",
    "# return value:\n",
    "# - your ID number (as an integer number)\n",
    "# ---------------------\n",
    "# --- General notes:\n",
    "# Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "# In the line following the '# YOUR CODE HERE' line, add your code\n",
    "# ---------------------\n",
    "def myId():\n",
    "    # YOUR CODE HERE\n",
    "    return 123456789\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "642e7f88f2c9d55f275d1af8bb64de02",
     "grade": false,
     "grade_id": "cell-c64165dd6b6c2ded",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'myName' method validation is successfull!\n",
      "your name is: Menahem Ovrutski\n",
      "--------------------------------------\n",
      "'myId' method validation is successfull!\n",
      "your id is: 123456789\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Important Notes:\n",
    "# - This test cell MUST NOT raise any exception\n",
    "# - It must pass all tests \n",
    "# - Do NOT change or delete this cell\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test of:\n",
    "## 'myName' and 'myId' implementation methods\n",
    "# It tests the correctness their implementation\n",
    "# Important Note: additional test might also be taken from our side.\n",
    "# --------------------------------------------------------\n",
    "aName = myName()\n",
    "aId = myId()\n",
    "assert aName is not None, 'no return student name'\n",
    "assert type(aName) is str, \"name is not a string: %r\" % aName\n",
    "print (\"'myName' method validation is successfull!\")\n",
    "print (\"your name is: %s\" %(aName))\n",
    "print (\"--------------------------------------\")\n",
    "assert aId is not None, 'no return student id'\n",
    "assert type(aId) is int, \"id is not an integer: %r\" % aId\n",
    "print (\"'myId' method validation is successfull!\")\n",
    "print (\"your id is: %d\" %(aId))\n",
    "## END OF 'myName' and 'myId' implementation validation\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 - Loading dataset - maximum possible points: 3\n",
    "The following cells perform 5 things:\n",
    "* Preceding step - import packages\n",
    "* step 1 - load the 'spam vs not-spam' dataset ----> Student's implementation - total 1 point\n",
    "* step 2 - split dataframe to X (feature vectors) and y (classes) ----> Student's implementation - total 1 point \n",
    "* step 3 - change classes values from string to number ----> Student's implementation - total 1 point \n",
    "* step 4 - split the dataset to a train-set and a test-set ----> run only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preceding Step - import packages\n",
    "This step is necessary in order to use external packages. <br/><br/>\n",
    "<u>Some of the exteranl packages include</u>: \n",
    "* pandas - which we use mainly for dataframes and series\n",
    "* numpy - which we use for advance operations, such as unique values of arrays\n",
    "* random - which we could use to select random value (like we studied in earlier exercises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPORT (PACKAGES) CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# - Do NOT change or delete the following imports:\n",
    "import sys\n",
    "import os\n",
    "import pathlib \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Note: do NOT add imports, such as sklearn, which could\n",
    "# answer the following questions.\n",
    "# --- add your imports here IF NEEDED:\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2 - step 1 - load the 'spam vs not-spam' dataset ----> Student's implementation - total 1 point\n",
    "<img src=\"./images/load_dataframe.jpg\" alt=\"load dataframe\" width=\"100\" align='center'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f07989e1ef8949fd5becf91a79420b42",
     "grade": false,
     "grade_id": "loading_dataframe",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 1\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: loadDataset \n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# The following is expected:\n",
    "# --- the method needs to return the dataset from the input csv file.\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - 'fileName' - full path of the csv fileName \n",
    "# ------------\n",
    "# return value:\n",
    "# - a dataframe structure containing the dataset\n",
    "# ---------------------\n",
    "# --- General notes:\n",
    "# Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "# In the line following the '# YOUR CODE HERE' line, add your code\n",
    "# ---------------------\n",
    "# --- Additional notes:\n",
    "# - You must use the parameters you've got. \n",
    "# - Do NOT define the parameters in the method.\n",
    "# --------------------- \n",
    "def loadDataset(fileName):\n",
    "    # YOUR CODE HERE\n",
    "    df = pd.read_csv(fileName)\n",
    "    return df\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote.\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "225e1d0bb699bf40dfd1ca1e36a7f631",
     "grade": true,
     "grade_id": "loading_dataframe_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing your implementation of the 'loadDataset' method ...\n",
      "----> The 'spam vs not-spam' dataframe object was loaded successfuly :-) \n",
      "\n",
      "The beginning (the head) of the dataframe:\n",
      "\n",
      "Note: Additional Tests might be executed on our side\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>make_wordFreq</th>\n",
       "      <th>address_wordFreq</th>\n",
       "      <th>all_wordFreq</th>\n",
       "      <th>3d_wordFreq</th>\n",
       "      <th>our_wordFreq</th>\n",
       "      <th>over_wordFreq</th>\n",
       "      <th>remove_wordFreq</th>\n",
       "      <th>internet_wordFreq</th>\n",
       "      <th>order_wordFreq</th>\n",
       "      <th>mail_wordFreq</th>\n",
       "      <th>...</th>\n",
       "      <th>semicol_wordFreq</th>\n",
       "      <th>paren_wordFreq</th>\n",
       "      <th>bracket_wordFreq</th>\n",
       "      <th>bang_wordFreq</th>\n",
       "      <th>dollar_wordFreq</th>\n",
       "      <th>pound_wordFreq</th>\n",
       "      <th>capitalLet_avg</th>\n",
       "      <th>capitalLet_long</th>\n",
       "      <th>capitalLet_total</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.666</td>\n",
       "      <td>10</td>\n",
       "      <td>180</td>\n",
       "      <td>not_spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.510</td>\n",
       "      <td>10</td>\n",
       "      <td>74</td>\n",
       "      <td>not_spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.718</td>\n",
       "      <td>11</td>\n",
       "      <td>55</td>\n",
       "      <td>not_spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3.426</td>\n",
       "      <td>72</td>\n",
       "      <td>819</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.428</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   make_wordFreq  address_wordFreq  all_wordFreq  3d_wordFreq  our_wordFreq  \\\n",
       "0           0.00              0.00          0.29          0.0          0.00   \n",
       "1           0.46              0.00          0.00          0.0          0.00   \n",
       "2           0.00              0.00          0.00          0.0          0.00   \n",
       "3           0.33              0.44          0.37          0.0          0.14   \n",
       "4           0.00              2.08          0.00          0.0          3.12   \n",
       "\n",
       "   over_wordFreq  remove_wordFreq  internet_wordFreq  order_wordFreq  \\\n",
       "0           0.00             0.00               0.00            0.00   \n",
       "1           0.00             0.00               0.00            0.00   \n",
       "2           0.00             0.00               0.00            0.00   \n",
       "3           0.11             0.00               0.07            0.97   \n",
       "4           0.00             1.04               0.00            0.00   \n",
       "\n",
       "   mail_wordFreq  ...  semicol_wordFreq  paren_wordFreq  bracket_wordFreq  \\\n",
       "0           0.00  ...             0.000           0.178               0.0   \n",
       "1           0.00  ...             0.000           0.125               0.0   \n",
       "2           0.00  ...             0.000           0.000               0.0   \n",
       "3           1.16  ...             0.006           0.159               0.0   \n",
       "4           0.00  ...             0.000           0.000               0.0   \n",
       "\n",
       "   bang_wordFreq  dollar_wordFreq  pound_wordFreq  capitalLet_avg  \\\n",
       "0          0.044            0.000            0.00           1.666   \n",
       "1          0.000            0.000            0.00           1.510   \n",
       "2          0.000            0.000            0.00           1.718   \n",
       "3          0.069            0.221            0.11           3.426   \n",
       "4          0.263            0.000            0.00           1.428   \n",
       "\n",
       "   capitalLet_long  capitalLet_total     class  \n",
       "0               10               180  not_spam  \n",
       "1               10                74  not_spam  \n",
       "2               11                55  not_spam  \n",
       "3               72               819      spam  \n",
       "4                4                20      spam  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Important Notes:\n",
    "# - This test cell MUST NOT raise any exception\n",
    "# - It must pass all tests to get the point ----- #\n",
    "# - Do NOT change or delete this cell\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 1\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test of:\n",
    "### --- Graded tests for the 'loadDataset' method \n",
    "# Important Note: additional test might also be taken from our side.\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetCsvFileName = folderName + os.sep + 'spam_notSpam.csv'\n",
    "# --------------------- \n",
    "print (\"Testing your implementation of the 'loadDataset' method ...\")\n",
    "dataset_forTesting = loadDataset(datasetCsvFileName)\n",
    "assert dataset_forTesting is not None, 'spam_notSpam object not initialized'\n",
    "assert isinstance(dataset_forTesting, pd.DataFrame), 'spam_notSpam object is not a dataframe'\n",
    "assert dataset_forTesting.empty == False, 'spam_notSpam dataframe object is empty'\n",
    "assert len(dataset_forTesting.columns)==58, 'spam_notSpam dataframe object is missing columns'\n",
    "assert len(dataset_forTesting.index)==4601, 'spam_notSpam dataframe object is missing rows'\n",
    "print (\"----> The 'spam vs not-spam' dataframe object was loaded successfuly :-) \\n\")\n",
    "dataset_forTesting=None\n",
    "print ('The beginning (the head) of the dataframe:')\n",
    "print ('\\nNote: Additional Tests might be executed on our side')\n",
    "loadDataset(datasetCsvFileName).head()\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2 - step 2 - split dataframe to X (feature vectors) and y (classes) ----> Student's implementation - total 1 point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "608d1ec6e8e9b31853108e36025a661b",
     "grade": false,
     "grade_id": "seperate_to_x_and_y",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 1\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: separateTo_X_and_y \n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# The following is expected:\n",
    "# ---- The method should separate the input dataset into two parts:\n",
    "# 1. X (feature vectors)  \n",
    "# 2. y (categories) \n",
    "# ------------\n",
    "# input parameters:\n",
    "# - dataset -  a dataframe structure, containing the dataset.\n",
    "# - classColName - the column name (string) containing the categories\n",
    "# ------------\n",
    "# return values (comma separated):\n",
    "# - X_featureVectores - a dataframe containing all feature vectors. \n",
    "#                       It should contain the input dataframe after removing the class column.\n",
    "#                       The index of the X_featureVectores should be the same as the input dataframe parameter.\n",
    "# - y_Categories      - a series of containing all class values per instance.\n",
    "#                       The index of the y_Categories series should be the same as the input dataframe.\n",
    "# ---------------------\n",
    "# --- General notes:\n",
    "# Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "# In the line following the '# YOUR CODE HERE' line, add your code\n",
    "# ---------------------\n",
    "# --- Additional notes:\n",
    "# - You must use the parameters you've got. \n",
    "# - Do NOT define the parameters in the method.\n",
    "# --------------------- \n",
    "def separateTo_X_and_y(dataset, classColName):\n",
    "    # YOUR CODE HERE\n",
    "    yCat = pd.Series(dataset[classColName], index=dataset.index)   \n",
    "    del dataset[classColName]\n",
    "    return dataset, yCat\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote.\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f8d4b2ae02953a94931be97a37884b9",
     "grade": true,
     "grade_id": "separateTo_X_and_y-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing your implementation of the 'separateTo_X_and_y' method ...\n",
      "----> The 'separateTo_X_and_y' test passed successfully :-) \n",
      "\n",
      "\n",
      "Additional Tests might be executed on our side\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Important Notes:\n",
    "# - This test cell MUST NOT raise any exception\n",
    "# - It must pass all tests to get the point ----- #\n",
    "# - Do NOT change or delete this cell\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 1\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test of:\n",
    "### --- Graded tests for the 'separateTo_X_and_y' method \n",
    "# Important Note: additional test might also be taken from our side.\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetCsvFileName = folderName + os.sep + 'spam_notSpam.csv'\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "print (\"Testing your implementation of the 'separateTo_X_and_y' method ...\")\n",
    "# --------------------- \n",
    "dataset_forTesting = loadDataset(datasetCsvFileName)\n",
    "X_vectors, y_categories = separateTo_X_and_y(dataset_forTesting, 'class')\n",
    "# ---------------------\n",
    "sameIndexes = lambda obj1,obj2: False not in (obj1.index.tolist()[n] == obj2.index.tolist()[n] for n in range(len(obj1.index))) \n",
    "assert X_vectors is not None, 'X_vectors object not initialized'\n",
    "assert isinstance(X_vectors, pd.DataFrame), 'X_vectors object is not a dataframe'\n",
    "assert X_vectors.empty == False, 'X_vectors dataframe object is empty'\n",
    "assert sameIndexes(X_vectors,dataset_forTesting), 'X_vectors should share the same indexes as the dataset'\n",
    "assert y_categories is not None, 'y_categories object not initialized'\n",
    "assert isinstance(y_categories, pd.Series), 'y_categories object is not a series'\n",
    "assert y_categories.empty == False, 'y_categories dataframe object is empty'\n",
    "assert sameIndexes(X_vectors,y_categories), 'X_vectors should share the same indexes as y_categories'\n",
    "print (\"----> The 'separateTo_X_and_y' test passed successfully :-) \\n\")\n",
    "print ('\\nAdditional Tests might be executed on our side')\n",
    "dataset_forTesting = None\n",
    "X_vectors = None\n",
    "y_categories = None\n",
    "# --------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2 - step 3 - change classes values from string to number ----> Student's implementation - total 1 point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9cab0a3ea6e38c47951e19e986ebfd31",
     "grade": false,
     "grade_id": "categories-to-nums",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 1\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: separateTo_X_and_y \n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# The following is expected:\n",
    "# ---- The method changes the input string categories to int categories.\n",
    "#      'not_spam' --> 0\n",
    "#      'spam'     --> 1\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - y_Categories -  a dataframe structure, containing the dataset.\n",
    "# - positiveClassName - the name of the category (string) of the positive class\n",
    "#                       * if the value of a cell does not equal positiveClassName, \n",
    "#                         it should be considered as negative.\n",
    "# ------------\n",
    "# return value: \n",
    "# - y_NumCategories - a series of containing all class values with numeric values per instance.\n",
    "#                       * each cell value, which equals the negativeClassName will recieve a value of 0 in the\n",
    "#                         output series.\n",
    "#                       * each cell value, which equals the positiveClassName will recieve a value of 1 in the\n",
    "#                         output series.\n",
    "#                       * the index should be the same of the input series.\n",
    "# ---------------------\n",
    "# --- General notes:\n",
    "# Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "# In the line following the '# YOUR CODE HERE' line, add your code\n",
    "# ---------------------\n",
    "# --- Additional notes:\n",
    "# - You must use the parameters you've got. \n",
    "# - Do NOT define the parameters in the method.\n",
    "# --------------------- \n",
    "def datasetCategoriesToNums(y_Categories, positiveClassName):\n",
    "    # YOUR CODE HERE\n",
    "    yCatNum = pd.Series(y_Categories, index=y_Categories.index)\n",
    "    for index, value in yCatNum.items():\n",
    "        if value == positiveClassName :\n",
    "            yCatNum.iloc[index] = 1\n",
    "        else :\n",
    "            yCatNum.iloc[index] = 0\n",
    "    return yCatNum\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote.\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d5cfbb886fb0ec632fe235d25755e20f",
     "grade": true,
     "grade_id": "categories-to-nums-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing your implementation of the 'datasetCategoriesToNums' method ...\n",
      "----> The 'datasetCategoriesToNums' test passed successfully :-) \n",
      "\n",
      "\n",
      "Additional Tests might be executed on our side\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Important Notes:\n",
    "# - This test cell MUST NOT raise any exception\n",
    "# - It must pass all tests to get the point ----- #\n",
    "# - Do NOT change or delete this cell\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 1\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test of:\n",
    "### --- Graded tests for the 'datasetCategoriesToNums' method \n",
    "# Important Note: additional test might also be taken from our side.\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetCsvFileName = folderName + os.sep + 'spam_notSpam.csv'\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "print (\"Testing your implementation of the 'datasetCategoriesToNums' method ...\")\n",
    "# --------------------- \n",
    "dataset_forTesting = loadDataset(datasetCsvFileName)\n",
    "X_vectors, y_categoriesB4 = separateTo_X_and_y(dataset_forTesting, 'class')\n",
    "y_categories = datasetCategoriesToNums(y_categoriesB4, 'spam')\n",
    "# --------------------- \n",
    "allValidVals = lambda arrValues,validVals: False not in (val in validVals for val in arrValues) \n",
    "sameIndexes = lambda obj1,obj2: False not in (obj1.index.tolist()[n] == obj2.index.tolist()[n] for n in range(len(obj1.index))) \n",
    "assert y_categories is not None, 'y_categories object not initialized'\n",
    "assert isinstance(y_categories, pd.Series), 'y_categories object is not a series'\n",
    "assert y_categories.empty == False, 'y_categories dataframe object is empty'\n",
    "assert sameIndexes(y_categories,y_categoriesB4), 'y_categories should share the same indexes as y_categoriesB4'\n",
    "assert allValidVals(np.unique(y_categories.values),(0,1)), 'classes should be only 0 or 1 (as an integer number)'\n",
    "print (\"----> The 'datasetCategoriesToNums' test passed successfully :-) \\n\")\n",
    "print ('\\nAdditional Tests might be executed on our side')\n",
    "dataset_forTesting = None\n",
    "X_vectors = None\n",
    "y_categories = None\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2 - step 4 - split the dataset to a train-set and a test-set ----> run only\n",
    "<img src=\"./images/train-test-split.png\" alt=\"train-test split\" width=\"100\" align='center'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e1ba142a8eb56c7d0c893905794f37fe",
     "grade": false,
     "grade_id": "train-test-split",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information after train-test split:\n",
      "The train-set includes 3680 instances and 3680 corresponding categories\n",
      "\n",
      "The test-set includes 921 instances and 921 corresponding categories\n",
      "\n",
      "First few rows of unified train-set:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>make_wordFreq</th>\n",
       "      <th>address_wordFreq</th>\n",
       "      <th>all_wordFreq</th>\n",
       "      <th>3d_wordFreq</th>\n",
       "      <th>our_wordFreq</th>\n",
       "      <th>over_wordFreq</th>\n",
       "      <th>remove_wordFreq</th>\n",
       "      <th>internet_wordFreq</th>\n",
       "      <th>order_wordFreq</th>\n",
       "      <th>mail_wordFreq</th>\n",
       "      <th>...</th>\n",
       "      <th>semicol_wordFreq</th>\n",
       "      <th>paren_wordFreq</th>\n",
       "      <th>bracket_wordFreq</th>\n",
       "      <th>bang_wordFreq</th>\n",
       "      <th>dollar_wordFreq</th>\n",
       "      <th>pound_wordFreq</th>\n",
       "      <th>capitalLet_avg</th>\n",
       "      <th>capitalLet_long</th>\n",
       "      <th>capitalLet_total</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2776</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.736</td>\n",
       "      <td>10</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>908</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.352</td>\n",
       "      <td>15</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4540</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.072</td>\n",
       "      <td>2.451</td>\n",
       "      <td>28</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>788</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.823</td>\n",
       "      <td>38</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2186</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.284</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.357</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      make_wordFreq  address_wordFreq  all_wordFreq  3d_wordFreq  \\\n",
       "2776           0.00               0.0          1.23          0.0   \n",
       "908            0.00               0.0          0.00          0.0   \n",
       "4540           0.44               0.0          0.00          0.0   \n",
       "788            0.00               0.0          0.00          0.0   \n",
       "2186           0.00               0.0          0.00          0.0   \n",
       "\n",
       "      our_wordFreq  over_wordFreq  remove_wordFreq  internet_wordFreq  \\\n",
       "2776          0.00            0.0              0.0                0.0   \n",
       "908           0.00            0.0              0.0                0.0   \n",
       "4540          0.89            0.0              0.0                0.0   \n",
       "788           0.00            0.0              0.0                0.0   \n",
       "2186          0.00            0.0              0.0                0.0   \n",
       "\n",
       "      order_wordFreq  mail_wordFreq  ...  semicol_wordFreq  paren_wordFreq  \\\n",
       "2776             0.0           0.00  ...               0.0           0.139   \n",
       "908              0.0           0.00  ...               0.0           0.336   \n",
       "4540             0.0           0.44  ...               0.0           0.000   \n",
       "788              0.0           0.00  ...               0.0           0.186   \n",
       "2186             0.0           0.00  ...               0.0           0.000   \n",
       "\n",
       "      bracket_wordFreq  bang_wordFreq  dollar_wordFreq  pound_wordFreq  \\\n",
       "2776               0.0          0.279            0.000           0.000   \n",
       "908                0.0          0.000            0.000           0.000   \n",
       "4540               0.0          0.944            0.145           0.072   \n",
       "788                0.0          0.000            0.000           0.000   \n",
       "2186               0.0          1.284            0.000           0.000   \n",
       "\n",
       "      capitalLet_avg  capitalLet_long  capitalLet_total  class  \n",
       "2776           1.736               10                66      0  \n",
       "908            2.352               15                40      0  \n",
       "4540           2.451               28               152      1  \n",
       "788            2.823               38               240      1  \n",
       "2186           1.357                5                19      1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# NO IMPLEMENTAION - DO NO CHANGE\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name1: trainTestSplit\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# What does the method do?\n",
    "# --- the method split the input dataset into train and test. \n",
    "#     - It does so using the sklearn built in method\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - X_vectors - a dataframe containing all feature vectors. \n",
    "# - y_categories - a series of containing all class values per instance.\n",
    "# - test_size_ratio - a number (0<number<1) of the wanted ratio of the dataset out of the dataset \n",
    "# - rand_state - a number, in order to guarantee reproducible results \n",
    "# ------------\n",
    "# return values (comma separated):\n",
    "# - X_train -  a dataframe containing all feature vectors of the train set\n",
    "# - X_test -  a dataframe containing all feature vectors of the test set\n",
    "# - y_train - a series of containing all class values per train instance\n",
    "# - y_test - a series of containing all class values per test instance\n",
    "# --------------------- \n",
    "def trainTestSplit(X_vectors, y_categories, test_size_ratio, rand_state):\n",
    "    return train_test_split(X_vectors, y_categories, test_size=test_size_ratio, random_state=rand_state)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name2: reAttachTrainSet\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# What does the method do?\n",
    "# --- the method split the input dataset into train and test. \n",
    "#     - It does so using the sklearn built in method\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - X_train -  a dataframe containing all feature vectors of the train set\n",
    "# - y_train - a series of containing all class values per train instance\n",
    "# ------------\n",
    "# return value:\n",
    "# - train_set - a reattached dataframe, consisting both feature vectors and categories.\n",
    "# --------------------- \n",
    "def reAttachTrainSet(X_train, y_train):\n",
    "    return pd.concat((X_train, y_train), axis=1)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Temporary imports:\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "# --------\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetCsvFileName = folderName + os.sep + 'spam_notSpam.csv'\n",
    "# --------------------- \n",
    "dataset_forTesting = loadDataset(datasetCsvFileName)\n",
    "X_vectors, y_categories = separateTo_X_and_y(dataset_forTesting, 'class')\n",
    "y_categories = datasetCategoriesToNums(y_categories, 'spam')\n",
    "X_train, X_test, y_train, y_test = trainTestSplit(X_vectors, y_categories, 0.2, 25)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "if 'datasets' in sys.modules:\n",
    "    del (datasets)\n",
    "if 'train_test_split' in sys.modules:\n",
    "    del (train_test_split)\n",
    "sys_modules = list(sys.modules.keys())\n",
    "for mdl in sys_modules:\n",
    "    if mdl.startswith('sklearn.'):\n",
    "        del(sys.modules[mdl]) \n",
    "del (sklearn)\n",
    "if 'sklearn' in sys.modules:\n",
    "    del (sys.modules['sklearn'])\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# display train-test split information\n",
    "# --------------------------------------------------------\n",
    "print ('Information after train-test split:')\n",
    "print('The train-set includes %d instances and %d corresponding categories\\n' %(X_train.shape[0],y_train.shape[0]))\n",
    "print('The test-set includes %d instances and %d corresponding categories\\n' %(X_test.shape[0],y_test.shape[0]))\n",
    "\n",
    "# --------------------------------------------------------\n",
    "## concatinate the X_train and y_train:\n",
    "# --------------------------------------------------------\n",
    "train_set = reAttachTrainSet(X_train, y_train)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "dataset_forTesting = None\n",
    "X_vectors = None\n",
    "y_categories = None\n",
    "X_train = None\n",
    "X_test = None\n",
    "y_train = None\n",
    "y_test = None\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Display the first few rows of the training-set:\n",
    "# --------------------------------------------------------\n",
    "print('First few rows of unified train-set:')\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 - Building a Bagging Classifier\n",
    "<img src=\"./images/bagging-classifier.jpeg\" alt=\"bagging-classifier\" width=\"400\" align='center'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3a - Bootstrap - maximum possible points: 8\n",
    "The following cells perform 2 methods:\n",
    "* step 1 - instance bootstrap ----> Student's implementation - total 4 point\n",
    "* step 2 - feature bootstrap ----> Student's implementation - total 4 point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3a - step 1 - instance bootstrap ----> Student's implementation - total 4 point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "678eca7748390713d38eb195317297f1",
     "grade": false,
     "grade_id": "instance-bootstrap",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 4\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: instanceBootStrap\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# What does the method do?\n",
    "# --- the method samples the dataset uniformly with replacements. \n",
    "#     * this means that there is a chance we could get the same instance more than once\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - X_train - a dataframe containing all training feature vectors. \n",
    "# - y_train - a series of containing all training class values per instance.\n",
    "# - sampleRatio - the ratio of the sampeling out of training set \n",
    "#               * we will derive the number of instances to sample from sampleRatio\n",
    "# ------------\n",
    "# return values (comma separated):\n",
    "# - X_trainSampled - a dataframe containing sampled training feature vectors. \n",
    "# - y_trainSampled - a series of containing Sampled training class values per instance.\n",
    "# Note: X_trainSampled should have the same index as y_trainSampled \n",
    "# --------------------- \n",
    "# --- General notes:\n",
    "# Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "# In the line following the '# YOUR CODE HERE' line, add your code\n",
    "# ---------------------\n",
    "# --- Additional notes:\n",
    "# - You must use the parameters you've got. \n",
    "# - Do NOT define the parameters in the method.\n",
    "# --------------------- \n",
    "def instanceBootStrap(X_train, y_train, sampleRatio):\n",
    "    # YOUR CODE HERE\n",
    "    samplesAmount = int(sampleRatio * len(X_train))\n",
    "    xTrainSampled = pd.DataFrame(columns = X_train.columns)    \n",
    "    yTrainSampled = pd.Series()\n",
    "    for i in range(samplesAmount):\n",
    "        index = random.randint(0, len(X_train) - 1)\n",
    "        xTrainSampled.loc[i] = X_train.iloc[index]\n",
    "        yTrainSampled.loc[i] = y_train.iloc[index]\n",
    "    return xTrainSampled, yTrainSampled\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote.\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d54b3e84c17d4bdfae8130c8e59a5cb8",
     "grade": true,
     "grade_id": "instance-nootStrap-test",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing your implementation of the 'instanceBootStrap' method ...\n",
      "----> The 'instanceBootStrap' test passed successfully :-) \n",
      "\n",
      "\n",
      "Additional Tests might be executed on our side\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Important Notes:\n",
    "# - This test cell MUST NOT raise any exception\n",
    "# - It must pass all tests to get the point ----- #\n",
    "# - Do NOT change or delete this cell\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 4\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test of:\n",
    "### --- Graded tests for the 'instanceBootStrap' method \n",
    "# Important Note: additional test might also be taken from our side.\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Temporary imports:\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "# --------\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetCsvFileName = folderName + os.sep + 'spam_notSpam.csv'\n",
    "# --------------------------------------------------------\n",
    "print (\"Testing your implementation of the 'instanceBootStrap' method ...\")\n",
    "dataset_forTesting = loadDataset(datasetCsvFileName)\n",
    "X_vectors, y_categories = separateTo_X_and_y(dataset_forTesting, 'class')\n",
    "y_categories = datasetCategoriesToNums(y_categories, 'spam')\n",
    "X_train, X_test, y_train, y_test = trainTestSplit(X_vectors, y_categories, 0.2, 35)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "if 'datasets' in sys.modules:\n",
    "    del (datasets)\n",
    "if 'train_test_split' in sys.modules:\n",
    "    del (train_test_split)\n",
    "sys_modules = list(sys.modules.keys())\n",
    "for mdl in sys_modules:\n",
    "    if mdl.startswith('sklearn.'):\n",
    "        del(sys.modules[mdl]) \n",
    "del (sklearn)\n",
    "if 'sklearn' in sys.modules:\n",
    "    del (sys.modules['sklearn'])\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "allValidVals = lambda arrValues,validVals: False not in (val in validVals for val in arrValues) \n",
    "sameIndexes = lambda obj1,obj2: False not in (obj1.index.tolist()[n] == obj2.index.tolist()[n] for n in range(len(obj1.index))) \n",
    "X_train_100 = X_train.iloc[:100,:]\n",
    "y_train_100 = y_train.iloc[:100]\n",
    "sampleRatio = 0.5\n",
    "X_trainSampled, y_trainSampled = instanceBootStrap(X_train_100, y_train_100, sampleRatio)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "assert X_trainSampled is not None, 'X_trainSampled object not initialized'\n",
    "assert isinstance(X_trainSampled, pd.DataFrame), 'X_trainSampled object is not a dataframe'\n",
    "assert X_trainSampled.empty == False, 'X_trainSampled dataframe object is empty'\n",
    "assert y_trainSampled is not None, 'y_trainSampled object not initialized'\n",
    "assert isinstance(y_trainSampled, pd.Series), 'y_trainSampled object is not a series'\n",
    "assert y_trainSampled.empty == False, 'y_trainSampled series object is empty'\n",
    "assert sameIndexes(X_trainSampled,y_trainSampled), 'X_trainSampled should share the same indexes as y_trainSampled'\n",
    "assert allValidVals(np.unique(y_categories.values),(0,1)), \"y_trainSampled's value should be only 0 or 1 (as an integer number)\"\n",
    "print (\"----> The 'instanceBootStrap' test passed successfully :-) \\n\")\n",
    "print ('\\nAdditional Tests might be executed on our side')\n",
    "dataset_forTesting = None\n",
    "X_vectors = None\n",
    "y_categories = None\n",
    "X_train = None\n",
    "X_test = None\n",
    "y_train = None\n",
    "y_test = None\n",
    "X_train_100 = None\n",
    "y_train_100 = None\n",
    "sampleRatio = None\n",
    "X_trainSampled = None\n",
    "y_trainSampled = None\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3a - step 2 - feature bootstrap ----> Student's implementation - total 4 point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "948f9ad2e06f5c6a52bfbee12f378fee",
     "grade": false,
     "grade_id": "feature-bootstrap",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 4\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: featureBootStrap\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# What does the method do?\n",
    "# --- the method samples the featureset uniformly with replacements. \n",
    "#     * this means that there is a chance we could choose the same feature twice \n",
    "#     * note that in the output dataframe, any feature which was already chosen,\n",
    "#            will be disregarded. In other words, such a case will result in less\n",
    "#            output features. For instance if we have 50 input features, and the sample\n",
    "#            ratio is 0.5, we should expect 25 sampled feature columns. But if one of the features\n",
    "#            was selected twice, we expect only 24 feature columns.\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - X_instances - a dataframe containing all feature vectors from the dataset.\n",
    "# - sampleRatio - the ratio of the sampeling out of feature set,\n",
    "#               * we will derive the number of features from sampleRatio\n",
    "# ------------\n",
    "# return value:\n",
    "# - X_instances_featureSampled - a dataframe containing feature vectors with sampled features. \n",
    "#                               * note the instances refer to the same instances as the input dataframe.\n",
    "#                               * the difference is in the columns (the selected features). \n",
    "# --------------------- \n",
    "# --- General notes:\n",
    "# Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "# In the line following the '# YOUR CODE HERE' line, add your code\n",
    "# ---------------------\n",
    "# --- Additional notes:\n",
    "# - You must use the parameters you've got. \n",
    "# - Do NOT define the parameters in the method.\n",
    "# --------------------- \n",
    "def featureBootStrap(X_instances, sampleRatio):\n",
    "    # YOUR CODE HERE\n",
    "    samplesAmount = int(sampleRatio * len(X_instances.columns))\n",
    "    xInstancesSampled = pd.DataFrame()\n",
    "    for i in range(samplesAmount):\n",
    "        index = random.randint(0, len(X_instances.columns) - 1)\n",
    "        xInstancesSampled.insert(i, X_instances.iloc[:,index].name, X_instances.iloc[:,index], allow_duplicates = True)\n",
    "    return xInstancesSampled\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote.\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6a18ff7bc2687c3f25c57d2490e25983",
     "grade": true,
     "grade_id": "feature-bootstrap-test",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing your implementation of the 'featureBootStrap' method ...\n",
      "\n",
      "----> The 'featureBootStrap' test passed successfully :-) \n",
      "\n",
      "\n",
      "Additional Tests might be executed on our side\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Important Notes:\n",
    "# - This test cell MUST NOT raise any exception\n",
    "# - It must pass all tests to get the point ----- #\n",
    "# - Do NOT change or delete this cell\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 4\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test of:\n",
    "### --- Graded tests for the 'featureBootStrap' method \n",
    "# Important Note: additional test might also be taken from our side.\n",
    "\n",
    "# --------------------------------------------------------\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetCsvFileName = folderName + os.sep + 'spam_notSpam.csv'\n",
    "# --------------------------------------------------------\n",
    "print (\"Testing your implementation of the 'featureBootStrap' method ...\")\n",
    "dataset_forTesting = loadDataset(datasetCsvFileName)\n",
    "X_vectors, y_categories = separateTo_X_and_y(dataset_forTesting, 'class')\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "allValidVals = lambda arrValues,validVals: False not in (val in validVals for val in arrValues) \n",
    "sameIndexes = lambda obj1,obj2: False not in (obj1.index.tolist()[n] == obj2.index.tolist()[n] for n in range(len(obj1.index))) \n",
    "\n",
    "columns = X_vectors.columns\n",
    "columns_50 = columns[:50] \n",
    "X_vectors_columns_50 = X_vectors[columns_50]\n",
    "sampleRatio = 0.5\n",
    "X_Sampled = featureBootStrap(X_vectors_columns_50, sampleRatio)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "assert X_Sampled is not None, 'X_Sampled object not initialized'\n",
    "assert isinstance(X_Sampled, pd.DataFrame), 'X_Sampled object is not a dataframe'\n",
    "assert X_Sampled.empty == False, 'X_Sampled dataframe object is empty'\n",
    "assert X_Sampled.shape[1] >10, 'X_Sampled dataframe object has a wrong number of sampled features'\n",
    "\n",
    "print (\"\\n----> The 'featureBootStrap' test passed successfully :-) \\n\")\n",
    "print ('\\nAdditional Tests might be executed on our side')\n",
    "dataset_forTesting = None\n",
    "X_vectors = None\n",
    "y_categories = None\n",
    "columns = None\n",
    "columns_50 = None\n",
    "X_vectors_columns_50 = None\n",
    "sampleRatio = None\n",
    "X_Sampled = None\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3b - Building a model  - maximum possible points: 4\n",
    "The following cells perform the following:\n",
    "* step 1 - decision stumps (and other classification utilities) ----> run only\n",
    "* step 2 - Bagging (fit)  ----> Student's implementation - total 4 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3b - step 1 - decision stumps (and other classification utilities) ----> run only\n",
    "<img src=\"./images/treeStumps.jpg\" alt=\"bagging-classifier\" width=\"400\" align='center'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0dae4c037b73f2eb3b660ab30ac616d8",
     "grade": false,
     "grade_id": "decision-stump-train",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A few prediction examples:\n",
      "test instance [0]: actual: 0, prediction(classifier1): 0, prediction(classifier2): 0\n",
      "test instance [1]: actual: 1, prediction(classifier1): 0, prediction(classifier2): 0\n",
      "test instance [2]: actual: 0, prediction(classifier1): 0, prediction(classifier2): 0\n",
      "test instance [3]: actual: 0, prediction(classifier1): 1, prediction(classifier2): 0\n",
      "test instance [4]: actual: 0, prediction(classifier1): 0, prediction(classifier2): 0\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# NO IMPLEMENTAION - DO NO CHANGE\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# class 1: DecisionStump\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# What does the method do?\n",
    "# --- wraps an api for decision stumps, so we have a unified api\n",
    "# ------------\n",
    "class DecisionStump():\n",
    "    def __init__(self):\n",
    "        self._decisionStump = DecisionTreeClassifier(max_depth=1)\n",
    "        \n",
    "    def fit(self,X_train,y_train):\n",
    "        self._decisionStump.fit(X_train,y_train)\n",
    "\n",
    "    def predict(self,X_test):\n",
    "        return self._decisionStump.predict(X_test)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# class2: ClassiferInstGen\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# What does the method do?\n",
    "# --- utility classifier to generate objects of the classification algorithm class   \n",
    "# ------------\n",
    "class ClassiferInstGen():\n",
    "    def __init__(self,classifierPyClass):\n",
    "        self._classifierPyClass = classifierPyClass\n",
    "        \n",
    "    def getNewClassifierPyObj(self):\n",
    "        return self._classifierPyClass()\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# class3: BootstrapFeatureClassifer\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# What does the method do?\n",
    "# --- container classifier to save model and bootstrap features    \n",
    "# ------------\n",
    "class BootstrapFeatureClassifer():\n",
    "    def __init__(self,trainModel,featureNames):\n",
    "        self.model = trainModel\n",
    "        self.featureNames = featureNames\n",
    "\n",
    "        \n",
    "# --------------------------------------------------------\n",
    "# method name1: trainBootstrapedClassificationModel\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# What does the method do?\n",
    "# --- trains a classification model which matches the sklearn API of fit and predict.\n",
    "#     - It does so using the sklearn built in method\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - X_sampled_train -  a dataframe containing all feature vectors of the train set\n",
    "# - y_train - a series of containing all class values per train instance\n",
    "# Note: the X_sampled_train, y_train parameters could be instance bootsraped, feature bootsraped, both or none\n",
    "# - classificationAlgo_pyClass - the python 'class' parameter of a classification algorithm \n",
    "#                                For instance, the above 'DecisionStump' class.\n",
    "#                                Note: passing the pyton class is similar to passing a method\n",
    "#                                      as a parameter. Each call to: classificationAlgo_pyClass()\n",
    "#                                      creates a new object (also called instance of the class)\n",
    "#                                      of the type of the class.  \n",
    "# ------------\n",
    "# return value:\n",
    "# - featuresTrainModelObj - an object including trained model and feature names \n",
    "# --------------------- \n",
    "def trainBootstrapedClassificationModel(X_sampled_train, y_train,classificationAlgo_pyClass):\n",
    "    classiferInstGen = ClassiferInstGen(classificationAlgo_pyClass)\n",
    "    classificationObj = classiferInstGen.getNewClassifierPyObj()\n",
    "    classificationObj.fit(X_sampled_train, y_train)\n",
    "    featuresTrainModelObj = BootstrapFeatureClassifer(classificationObj,X_sampled_train.columns)\n",
    "    return featuresTrainModelObj\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name2: classifierPredict\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# What does the method do?\n",
    "# --- predict test examples using a classification model (which corresponds to sklearn classifier APIs)\n",
    "#     - It does so using the sklearn built in method\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - X_test -  a dataframe containing feature vectors of the test set\n",
    "# - classification_obj - trained classificaion model (which corresponds to sklearn classifier APIs)\n",
    "# ------------\n",
    "# return value:\n",
    "# - yHat - a series of the predictions for each test instance  \n",
    "# --------------------- trainBootstrapedFeatureModel(X_sampled_train, y_train,classificationAlgo_pyClass)\n",
    "def classifierPredict(X_test, featuresTrainModelObj):\n",
    "    X_adapted = X_test[featuresTrainModelObj.featureNames]\n",
    "    predictions = featuresTrainModelObj.model.predict(X_adapted)\n",
    "    yHat = pd.Series(data=predictions,index=X_test.index)\n",
    "    return yHat\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Temporary imports:\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# --------\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetCsvFileName = folderName + os.sep + 'spam_notSpam.csv'\n",
    "# --------------------- \n",
    "dataset_forTesting = loadDataset(datasetCsvFileName)\n",
    "X_vectors, y_categories = separateTo_X_and_y(dataset_forTesting, 'class')\n",
    "y_categories = datasetCategoriesToNums(y_categories, 'spam')\n",
    "X_train, X_test, y_train, y_test = trainTestSplit(X_vectors, y_categories, 0.2, 11)\n",
    "X_train_1st_k = X_train.iloc[:1000,:] \n",
    "y_train_1st_k = y_train.iloc[:1000]\n",
    "X_train_2nd_k = X_train.iloc[1000:2000,:] \n",
    "y_train_2nd_k = y_train.iloc[1000:2000]\n",
    "classificationModel1=trainBootstrapedClassificationModel(X_train_1st_k, y_train_1st_k,DecisionStump)\n",
    "classificationModel2=trainBootstrapedClassificationModel(X_train_2nd_k, y_train_2nd_k,DecisionStump)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# show usages of functions\n",
    "# --------------------------------------------------------\n",
    "print ('A few prediction examples:')\n",
    "nExamples=5\n",
    "\n",
    "y_hat1 = classifierPredict(X_test.iloc[:nExamples,:], classificationModel1)\n",
    "y_hat2 = classifierPredict(X_test.iloc[:nExamples,:], classificationModel2)\n",
    "for nInd in range(nExamples):\n",
    "    print ('test instance [%d]: actual: %r, prediction(classifier1): %r, prediction(classifier2): %r' %(nInd,y_test.iloc[nInd],y_hat1.iloc[nInd],y_hat2.iloc[nInd]))\n",
    "# --------------------------------------------------------\n",
    "if 'datasets' in sys.modules:\n",
    "    del (datasets)\n",
    "if 'train_test_split' in sys.modules:\n",
    "    del (train_test_split)\n",
    "if 'DecisionTreeClassifier' in sys.modules:\n",
    "    del (DecisionTreeClassifier)\n",
    "sys_modules = list(sys.modules.keys())\n",
    "for mdl in sys_modules:\n",
    "    if mdl.startswith('sklearn.'):\n",
    "        del(sys.modules[mdl]) \n",
    "del (sklearn)\n",
    "if 'sklearn' in sys.modules:\n",
    "    del (sys.modules['sklearn'])\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "dataset_forTesting = None\n",
    "X_vectors = None\n",
    "y_categories = None\n",
    "X_train = None\n",
    "X_test = None\n",
    "y_train = None\n",
    "y_test = None\n",
    "y_hat1 = None\n",
    "y_hat2 = None\n",
    "X_train_1st_k = None \n",
    "y_train_1st_k = None\n",
    "X_train_2nd_k = None \n",
    "y_train_2nd_k = None\n",
    "classificationModel1=None\n",
    "classificationModel2=None\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3b - step 2 - Bagging (fit)  ----> Student's implementation - total 4 points\n",
    "<img src=\"./images/bags.jpg\" alt=\"The bagging operation\" width=\"200\" align='center'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ae5e1282bfd518ff737e46ecda8e11e",
     "grade": false,
     "grade_id": "bagging-fit",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 4\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: baggingFit\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# The following is expected:\n",
    "# --- the method needs to return the a list of models created after bootstraping instances & features.\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - X_train - a dataframe containing all feature vectors of the train set\n",
    "# - y_train - a series of containing all class values per train instance\n",
    "# - instanceSampleRatio - the ratio of the sampeling out of training set, \n",
    "#                        * we will pass it on as a parameter, in order to sample instances.\n",
    "#                        - if instanceSampleRatio<=0, no instance bootstrap is done, and we leave\n",
    "#                          the training instances with no change.\n",
    "# - featureSampleRatio - the ratio of the sampeling out of feature set,\n",
    "#                        * we will pass it on as a parameter, in order to sample features.\n",
    "#                        - if featureSampleRatio<=0, no feature bootstrap is done, and we leave\n",
    "#                          the features with no change.\n",
    "# - classificationAlgo_pyClass - the python 'class' parameter of a classification algorithm \n",
    "#                                For instance, the above 'DecisionStump' class.\n",
    "#                                Note: passing the pyton class is similar to passing a method\n",
    "#                                      as a parameter.    \n",
    "# - numModels - number of models to train in bagging\n",
    "# Note: the X_train, y_train parameters could be instance bootsraped, feature bootsraped or both\n",
    "# ------------\n",
    "# return value:\n",
    "# - a list of trained models \n",
    "#  notes:\n",
    "#        * the number of models are detrminded by the input parameter \n",
    "# ---------------------\n",
    "# --- General notes:\n",
    "# Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "# In the line following the '# YOUR CODE HERE' line, add your code\n",
    "# ---------------------\n",
    "# --- Additional notes:\n",
    "# - You must use the parameters you've got. \n",
    "# - Do NOT define the parameters in the method.\n",
    "# --------------------------------------------------------\n",
    "def baggingFit(X_train, y_train, instanceSampleRatio, featureSampleRatio, classificationAlgo_pyClass, numModels):\n",
    "    # note that FOR EACH bootstraped train set and/or feature set you need to create a classifier using:\n",
    "    # classificationModel=trainBootstrapedClassificationModel(X_train_bootstraped, y_train_corrolated_labels,classificationAlgo_pyClass)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    instanceSamplesAmount = 0\n",
    "    featureSamplesAmount = 0\n",
    "    if(instanceSampleRatio >= 0):\n",
    "        instanceSamplesAmount = int(instanceSampleRatio * len(X_train))\n",
    "    if(featureSampleRatio >= 0):\n",
    "        featureSamplesAmount = int(featureSampleRatio * len(X_train.columns))\n",
    "    classificationModel = []\n",
    "    for i in range(numModels):\n",
    "        xTrainCurrentFeature = featureBootStrap(X_train, featureSampleRatio)\n",
    "        xTrainCurrent, yTrainCurrent = instanceBootStrap(xTrainCurrentFeature, y_train, instanceSampleRatio)\n",
    "        classificationCurrModel = trainBootstrapedClassificationModel(xTrainCurrent, yTrainCurrent, classificationAlgo_pyClass)\n",
    "        classificationModel.append(classificationCurrModel)\n",
    "    return classificationModel\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote.\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "86ecc8568c150ec0909a409c70b4d08b",
     "grade": true,
     "grade_id": "cell-fcf5b9299c2d8e0a",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing your implementation of the 'baggingFit' method ...\n",
      "check basic 'baggingFit' output validation ...\n",
      "trying to create inner bagged models prediction ...\n",
      "----> The 'baggingFit' test passed successfully :-) \n",
      "\n",
      "\n",
      "Additional Tests might be executed on our side\n",
      "\n",
      "----------------------\n",
      "A few prediction examples:\n",
      "test instance [0]: actual: 1, predictions: '[bag-model 0]: 1; [bag-model 1]: 0; [bag-model 2]: 1'\n",
      "test instance [1]: actual: 1, predictions: '[bag-model 0]: 0; [bag-model 1]: 0; [bag-model 2]: 1'\n",
      "test instance [2]: actual: 0, predictions: '[bag-model 0]: 0; [bag-model 1]: 0; [bag-model 2]: 0'\n",
      "test instance [3]: actual: 1, predictions: '[bag-model 0]: 1; [bag-model 1]: 1; [bag-model 2]: 1'\n",
      "test instance [4]: actual: 0, predictions: '[bag-model 0]: 0; [bag-model 1]: 0; [bag-model 2]: 0'\n",
      "test instance [5]: actual: 0, predictions: '[bag-model 0]: 0; [bag-model 1]: 0; [bag-model 2]: 1'\n",
      "test instance [6]: actual: 1, predictions: '[bag-model 0]: 1; [bag-model 1]: 1; [bag-model 2]: 1'\n",
      "test instance [7]: actual: 0, predictions: '[bag-model 0]: 0; [bag-model 1]: 0; [bag-model 2]: 1'\n",
      "test instance [8]: actual: 0, predictions: '[bag-model 0]: 0; [bag-model 1]: 0; [bag-model 2]: 0'\n",
      "test instance [9]: actual: 0, predictions: '[bag-model 0]: 1; [bag-model 1]: 0; [bag-model 2]: 1'\n",
      "test instance [10]: actual: 0, predictions: '[bag-model 0]: 0; [bag-model 1]: 0; [bag-model 2]: 0'\n",
      "test instance [11]: actual: 0, predictions: '[bag-model 0]: 1; [bag-model 1]: 0; [bag-model 2]: 1'\n",
      "test instance [12]: actual: 1, predictions: '[bag-model 0]: 0; [bag-model 1]: 0; [bag-model 2]: 1'\n",
      "test instance [13]: actual: 1, predictions: '[bag-model 0]: 1; [bag-model 1]: 1; [bag-model 2]: 1'\n",
      "test instance [14]: actual: 0, predictions: '[bag-model 0]: 1; [bag-model 1]: 0; [bag-model 2]: 1'\n",
      "test instance [15]: actual: 1, predictions: '[bag-model 0]: 1; [bag-model 1]: 1; [bag-model 2]: 1'\n",
      "test instance [16]: actual: 0, predictions: '[bag-model 0]: 1; [bag-model 1]: 0; [bag-model 2]: 0'\n",
      "test instance [17]: actual: 0, predictions: '[bag-model 0]: 1; [bag-model 1]: 0; [bag-model 2]: 1'\n",
      "test instance [18]: actual: 0, predictions: '[bag-model 0]: 0; [bag-model 1]: 0; [bag-model 2]: 1'\n",
      "test instance [19]: actual: 0, predictions: '[bag-model 0]: 0; [bag-model 1]: 0; [bag-model 2]: 0'\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Important Notes:\n",
    "# - This test cell MUST NOT raise any exception\n",
    "# - It must pass all tests to get the point ----- #\n",
    "# - Do NOT change or delete this cell\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 4\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test of:\n",
    "### --- Graded tests for the 'baggingFit' method \n",
    "# Important Note: additional test might also be taken from our side.\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Temporary imports:\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# --------\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetCsvFileName = folderName + os.sep + 'spam_notSpam.csv'\n",
    "# --------------------- \n",
    "print (\"Testing your implementation of the 'baggingFit' method ...\")\n",
    "dataset_forTesting = loadDataset(datasetCsvFileName)\n",
    "X_vectors, y_categories = separateTo_X_and_y(dataset_forTesting, 'class')\n",
    "y_categories = datasetCategoriesToNums(y_categories, 'spam')\n",
    "X_train, X_test, y_train, y_test = trainTestSplit(X_vectors, y_categories, 0.2, 25)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "allValidVals = lambda arrValues,validVals: False not in (val in validVals for val in arrValues) \n",
    "sameIndexes = lambda obj1,obj2: False not in (obj1.index.tolist()[n] == obj2.index.tolist()[n] for n in range(len(obj1.index))) \n",
    "innerElementTupple = lambda arrValues: False not in (isinstance(elem,tuple) for elem in arrValues)\n",
    "# --------------------------------------------------------\n",
    "instanceSampleRatio = 0.1\n",
    "featureSampleRatio = 0.5\n",
    "numModels = 3\n",
    "classification_PyClass = DecisionStump\n",
    "baggedModels =  baggingFit(X_train, y_train, instanceSampleRatio, featureSampleRatio, classification_PyClass, numModels)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "print (\"check basic 'baggingFit' output validation ...\")\n",
    "assert baggedModels is not None, 'baggedModels object not initialized'\n",
    "assert isinstance(baggedModels, list), 'baggedModels object is not a list'\n",
    "assert None not in baggedModels, 'baggedModels should not include None elements'\n",
    "assert False not in [isinstance(elem,BootstrapFeatureClassifer) for elem in baggedModels], 'baggedModels should include only DecisionStump objects'\n",
    "\n",
    "print ('trying to create inner bagged models prediction ...')\n",
    "nExamples=20\n",
    "y_hat_arr = [classifierPredict(X_test.iloc[:nExamples],model) for model in baggedModels]\n",
    "assert False not in [allValidVals(y_hat.values,(0,1)) for y_hat in y_hat_arr], 'something went wrong with bagging inner models - invalid values found (valid values: 0 or 1)'\n",
    "\n",
    "print (\"----> The 'baggingFit' test passed successfully :-) \\n\")\n",
    "print ('\\nAdditional Tests might be executed on our side')\n",
    "\n",
    "print ('\\n----------------------')\n",
    "print ('A few prediction examples:')\n",
    "for nInd in range(nExamples):\n",
    "    predictions = '; '.join('[bag-model %d]: %r' %(nPred,y_hat_arr[nPred].iloc[nInd]) for nPred in range(len(y_hat_arr)))\n",
    "    print ('test instance [%d]: actual: %r, predictions: %r' %(nInd,y_test.iloc[nInd],predictions))\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "if 'datasets' in sys.modules:\n",
    "    del (datasets)\n",
    "if 'train_test_split' in sys.modules:\n",
    "    del (train_test_split)\n",
    "if 'DecisionTreeClassifier' in sys.modules:\n",
    "    del (DecisionTreeClassifier)\n",
    "sys_modules = list(sys.modules.keys())\n",
    "for mdl in sys_modules:\n",
    "    if mdl.startswith('sklearn.'):\n",
    "        del(sys.modules[mdl]) \n",
    "del (sklearn)\n",
    "if 'sklearn' in sys.modules:\n",
    "    del (sys.modules['sklearn'])\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "dataset_forTesting = None\n",
    "X_vectors = None\n",
    "y_categories = None\n",
    "X_train = None\n",
    "X_test = None\n",
    "y_train = None\n",
    "y_test = None\n",
    "y_hat = None\n",
    "\n",
    "instanceSampleRatio = None\n",
    "featureSampleRatio = None\n",
    "numModels = None\n",
    "classification_PyClass = None\n",
    "baggedModels = None\n",
    "\n",
    "nExamples = None\n",
    "y_hat_arr = None\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4 - Prediction -  maximum possible points: 3\n",
    "The following cells perform the following:\n",
    "* step 1 - predict (voting)    ----> Student's implementation - total 3 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2731d5d8644eff28931755a6472cb658",
     "grade": false,
     "grade_id": "bagging-predict",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 2\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: baggingPredict\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# The following is expected:\n",
    "# --- the method needs to return the predicted value for each test instances, \n",
    "#     based on the bagged trained models \n",
    "# ------------\n",
    "# input parameters:\n",
    "# - X_test -  a dataframe containing feature vectors of the test set\n",
    "# - baggingModels - the list of bagged models returned from 'baggingFit'\n",
    "# ------------\n",
    "# return value:\n",
    "# - y_hat - a series of the prediction, with the same index as X_test \n",
    "#  notes:\n",
    "#        * the number of models are detrminded by the input parameter \n",
    "# ---------------------\n",
    "# --- General notes:\n",
    "# Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "# In the line following the '# YOUR CODE HERE' line, add your code\n",
    "# ---------------------\n",
    "# --- Additional notes:\n",
    "# - You must use the parameters you've got. \n",
    "# - Do NOT define the parameters in the method.\n",
    "# --------------------------------------------------------\n",
    "def baggingPredict(X_test, baggingModels):\n",
    "    # note that FOR EACH model in baggingModels, predict the value using:\n",
    "    # y_test=classifierPredict(X_test, baggingModel)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    yHatArray = pd.DataFrame([classifierPredict(X_test, model) for model in baggingModels]).T\n",
    "    yHat = yHatArray[0]\n",
    "    for i in range(len(yHat)):\n",
    "        count = 0\n",
    "        for j in range(len(yHatArray.columns)):\n",
    "            if(yHatArray[j].iloc[i]==0):\n",
    "                count = count + 1\n",
    "        if(len(yHatArray.columns) - count >= count):\n",
    "            yHat[i] = 1\n",
    "        else:\n",
    "            yHat[i] = 0\n",
    "        return yHat\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote.\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eacc32a46056c90bd031c2b2e6414d82",
     "grade": true,
     "grade_id": "bagging-predict-test",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check basic 'baggingPredict' output validation (part 1) ...\n",
      "----> The 'baggingPredict' test passed successfully :-) \n",
      "\n",
      "\n",
      "Additional Tests might be executed on our side\n",
      "check basic 'baggingPredict' output validation (part 2) ...\n",
      "----> The 'baggingPredict' test passed successfully :-) \n",
      "\n",
      "\n",
      "Additional Tests might be executed on our side\n",
      "\n",
      "----------------------\n",
      "A few prediction examples:\n",
      "test instance [0]: actual: 1, predictions: 1\n",
      "test instance [1]: actual: 1, predictions: 1\n",
      "test instance [2]: actual: 0, predictions: 0\n",
      "test instance [3]: actual: 1, predictions: 1\n",
      "test instance [4]: actual: 0, predictions: 0\n",
      "test instance [5]: actual: 0, predictions: 1\n",
      "test instance [6]: actual: 1, predictions: 1\n",
      "test instance [7]: actual: 0, predictions: 1\n",
      "test instance [8]: actual: 0, predictions: 0\n",
      "test instance [9]: actual: 0, predictions: 1\n",
      "test instance [10]: actual: 0, predictions: 0\n",
      "test instance [11]: actual: 0, predictions: 0\n",
      "test instance [12]: actual: 1, predictions: 1\n",
      "test instance [13]: actual: 1, predictions: 1\n",
      "test instance [14]: actual: 0, predictions: 1\n",
      "test instance [15]: actual: 1, predictions: 1\n",
      "test instance [16]: actual: 0, predictions: 0\n",
      "test instance [17]: actual: 0, predictions: 0\n",
      "test instance [18]: actual: 0, predictions: 1\n",
      "test instance [19]: actual: 0, predictions: 0\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL (PART 1)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Important Notes:\n",
    "# - This test cell MUST NOT raise any exception\n",
    "# - It must pass all tests to get the point ----- #\n",
    "# - Do NOT change or delete this cell\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 3\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test of:\n",
    "### --- Graded tests for the 'baggingPredict' method \n",
    "# Important Note: additional test might also be taken from our side.\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Temporary imports:\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# --------\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetCsvFileName = folderName + os.sep + 'spam_notSpam.csv'\n",
    "# --------------------- \n",
    "dataset_forTesting = loadDataset(datasetCsvFileName)\n",
    "X_vectors, y_categories = separateTo_X_and_y(dataset_forTesting, 'class')\n",
    "y_categories = datasetCategoriesToNums(y_categories, 'spam')\n",
    "X_train, X_test, y_train, y_test = trainTestSplit(X_vectors, y_categories, 0.2, 25)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "allValidVals = lambda arrValues,validVals: False not in (val in validVals for val in arrValues) \n",
    "sameIndexes = lambda obj1,obj2: False not in (obj1.index.tolist()[n] == obj2.index.tolist()[n] for n in range(len(obj1.index))) \n",
    "innerElementTupple = lambda arrValues: False not in (isinstance(elem,tuple) for elem in arrValues)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "\n",
    "print (\"check basic 'baggingPredict' output validation (part 1) ...\")\n",
    "instanceSampleRatio = 0.1\n",
    "featureSampleRatio = 0.5\n",
    "numModels = 10\n",
    "classification_PyClass = DecisionStump\n",
    "baggedModels =  baggingFit(X_train, y_train, instanceSampleRatio, featureSampleRatio, classification_PyClass, numModels)\n",
    "yHat = baggingPredict(X_test, baggedModels)\n",
    "assert yHat is not None, 'yHat object not initialized'\n",
    "assert isinstance(yHat, pd.Series), 'yHat object is not a pandas series'\n",
    "assert None not in yHat.values, 'yHat should not include None elements'\n",
    "\n",
    "print (\"----> The 'baggingPredict' test passed successfully :-) \\n\")\n",
    "print ('\\nAdditional Tests might be executed on our side')\n",
    "# --------------------------------------------------------\n",
    "print (\"check basic 'baggingPredict' output validation (part 2) ...\")\n",
    "assert allValidVals(yHat.values,(0,1)), 'prediction err - something went wrong with bagging inner models - invalid values found (valid values: 0 or 1)'\n",
    "\n",
    "print (\"----> The 'baggingPredict' test passed successfully :-) \\n\")\n",
    "print ('\\nAdditional Tests might be executed on our side')\n",
    "\n",
    "print ('\\n----------------------')\n",
    "print ('A few prediction examples:')\n",
    "nExamples = 20\n",
    "for nInd in range(nExamples):\n",
    "    print ('test instance [%d]: actual: %r, predictions: %r' %(nInd,y_test.iloc[nInd],yHat.iloc[nInd]))\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "if 'datasets' in sys.modules:\n",
    "    del (datasets)\n",
    "if 'train_test_split' in sys.modules:\n",
    "    del (train_test_split)\n",
    "if 'DecisionTreeClassifier' in sys.modules:\n",
    "    del (DecisionTreeClassifier)\n",
    "sys_modules = list(sys.modules.keys())\n",
    "for mdl in sys_modules:\n",
    "    if mdl.startswith('sklearn.'):\n",
    "        del(sys.modules[mdl]) \n",
    "del (sklearn)\n",
    "if 'sklearn' in sys.modules:\n",
    "    del (sys.modules['sklearn'])\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "dataset_forTesting = None\n",
    "X_vectors = None\n",
    "y_categories = None\n",
    "X_train = None\n",
    "X_test = None\n",
    "y_train = None\n",
    "y_test = None\n",
    "y_hat = None\n",
    "yHat = None\n",
    "\n",
    "instanceSampleRatio = None\n",
    "featureSampleRatio = None\n",
    "numModels = None\n",
    "classification_PyClass = None\n",
    "baggedModels = None\n",
    "\n",
    "nExamples = None\n",
    "y_hat_arr = None\n",
    "# --------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5 - Evaluation - maximum possible points: 2\n",
    "The following cells perform the following:\n",
    "* step 1 - evaluate confusion matrix ----> run only\n",
    "* step 2 - evaluate precision  ----> Student's implementation - total 1 points\n",
    "* step 3 - evaluate recall     ----> Student's implementation - total 1 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 5 - step 1 - evaluate confusion matrix ----> run only\n",
    "<img src=\"./images/confusion_matrix.jpg\" alt=\"confusion_matrix\" width=\"300\" align='center'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf2aeaf3bcec6acf67ed2a7207d24a8b",
     "grade": false,
     "grade_id": "confusion-matrix",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n",
      "\tpred-0\tpred-1\n",
      "is-0\tTN=406\tFP=139\n",
      "is-1\tFN=92\tTP=284\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# NO IMPLEMENTAION - DO NO CHANGE\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# methos: getConfusionMatrix\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# What does the method do?\n",
    "# --- compute the 4 values of the confusion matrix: TN, FP, FN, TP\n",
    "#     - It does so using the sklearn built in method\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - y_hat -  a series of containing all predicted class values per test instance\n",
    "# - y_test - a series of containing all class values per test instance\n",
    "# ------------\n",
    "# return values (comma seperated):\n",
    "# - TN - True negatives - number of instances, for which the actual value (from y_test) \n",
    "#                         is 0 (negative class, not_spam in our dataset) and \n",
    "#                         the predicted value (from y_hat) is also 0.\n",
    "# - FP - True negatives - number of instances, for which the actual value (from y_test) is 0, but \n",
    "#                         the predicted value (from y_hat) is 1 (positive class, spam in our dataset).\n",
    "# - FN - False negatives - number of instances, for which the actual value (from y_test) is 1, but                          \n",
    "#                         the predicted value (from y_hat) is 0.\n",
    "# - TP - False negatives - number of instances, for which the actual value (from y_test) is 1 and                          \n",
    "#                         the predicted value (from y_hat) is also 1.\n",
    "# --------------------- \n",
    "def getConfusionMatrix(y_hat,y_test):\n",
    "    TN = len([1 for ind in range(len(y_test)) if y_test.iloc[ind]==0 and y_hat.iloc[ind]==0])\n",
    "    FP = len([1 for ind in range(len(y_test)) if y_test.iloc[ind]==0 and y_hat.iloc[ind]==1])\n",
    "    FN = len([1 for ind in range(len(y_test)) if y_test.iloc[ind]==1 and y_hat.iloc[ind]==0])\n",
    "    TP = len([1 for ind in range(len(y_test)) if y_test.iloc[ind]==1 and y_hat.iloc[ind]==1])\n",
    "    return TN,FP,FN,TP\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Temporary imports:\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# --------\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetCsvFileName = folderName + os.sep + 'spam_notSpam.csv'\n",
    "# --------------------- \n",
    "dataset_forTesting = loadDataset(datasetCsvFileName)\n",
    "X_vectors, y_categories = separateTo_X_and_y(dataset_forTesting, 'class')\n",
    "y_categories = datasetCategoriesToNums(y_categories, 'spam')\n",
    "X_train, X_test, y_train, y_test = trainTestSplit(X_vectors, y_categories, 0.2, 11)\n",
    "instanceSampleRatio = 0.1\n",
    "featureSampleRatio = 0.5\n",
    "numModels = 10\n",
    "classification_PyClass = DecisionStump\n",
    "baggedModels =  baggingFit(X_train, y_train, instanceSampleRatio, featureSampleRatio, classification_PyClass, numModels)\n",
    "y_hat = baggingPredict(X_test, baggedModels)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "numTN,numFP,numFN,numTP = getConfusionMatrix(y_hat,y_test)\n",
    "print ('confusion matrix:')\n",
    "print ('\\tpred-0\\tpred-1')\n",
    "print ('is-0\\tTN=%d\\tFP=%d' %(numTN,numFP))\n",
    "print ('is-1\\tFN=%d\\tTP=%d' %(numFN,numTP))\n",
    "# --------------------------------------------------------\n",
    "if 'datasets' in sys.modules:\n",
    "    del (datasets)\n",
    "if 'train_test_split' in sys.modules:\n",
    "    del (train_test_split)\n",
    "if 'DecisionTreeClassifier' in sys.modules:\n",
    "    del (DecisionTreeClassifier)\n",
    "sys_modules = list(sys.modules.keys())\n",
    "for mdl in sys_modules:\n",
    "    if mdl.startswith('sklearn.'):\n",
    "        del(sys.modules[mdl]) \n",
    "del (sklearn)\n",
    "if 'sklearn' in sys.modules:\n",
    "    del (sys.modules['sklearn'])\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "dataset_forTesting = None\n",
    "X_vectors = None\n",
    "y_categories = None\n",
    "X_train = None\n",
    "X_test = None\n",
    "y_train = None\n",
    "y_test = None\n",
    "\n",
    "yHat = None\n",
    "\n",
    "instanceSampleRatio = None\n",
    "featureSampleRatio = None\n",
    "numModels = None\n",
    "classification_PyClass = None\n",
    "baggedModels = None\n",
    "\n",
    "nExamples = None\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 5 - step 2 - evaluate precision  ----> Student's implementation - total 1 points\n",
    "<img src=\"./images/confusion_matrix-precision-recall.jpg\" alt=\"confusion_matrix-precision-recall\" width=\"300\" align='center'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5b69474bfc34b04f54ed4ba3231fe6ca",
     "grade": false,
     "grade_id": "precision",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 5\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: getPrecision\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# The following is expected:\n",
    "# --- the method needs to return the precision for class 1 (spam in out dataset)\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - y_hat -  a series of containing all predicted class values per test instance\n",
    "# - y_test - a series of containing all class values per test instance\n",
    "# ------------\n",
    "# return value:\n",
    "# - precision value\n",
    "# ---------------------\n",
    "# --- General notes:\n",
    "# Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "# In the line following the '# YOUR CODE HERE' line, add your code\n",
    "# ---------------------\n",
    "# --- Additional notes:\n",
    "# - You must use the parameters you've got. \n",
    "# - Do NOT define the parameters in the method.\n",
    "# --------------------------------------------------------\n",
    "\n",
    "def getPrecision(y_hat,y_test):\n",
    "    # note that you could use getConfusionMatrix(y_hat,y_test) to make it simpler\n",
    "    # YOUR CODE HERE\n",
    "    TN,FP,FN,TP = getConfusionMatrix(y_hat,y_test)\n",
    "    result = TP / (TP + FP)\n",
    "    return result\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote.\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7711af4832957f7db47679264b406596",
     "grade": true,
     "grade_id": "precision-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check basic 'getPrecision' output validation ...\n",
      "pricision=0.9659863945578231\n",
      "----> The 'getPrecision' test passed successfully :-) \n",
      "\n",
      "\n",
      "Additional Tests might be executed on our side\n",
      "\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Important Notes:\n",
    "# - This test cell MUST NOT raise any exception\n",
    "# - It must pass all tests to get the point ----- #\n",
    "# - Do NOT change or delete this cell\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 1\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test of:\n",
    "### --- Graded tests for the 'getPrecision' method \n",
    "# Important Note: additional test might also be taken from our side.\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Temporary imports:\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# --------\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetCsvFileName = folderName + os.sep + 'spam_notSpam.csv'\n",
    "# --------------------- \n",
    "dataset_forTesting = loadDataset(datasetCsvFileName)\n",
    "X_vectors, y_categories = separateTo_X_and_y(dataset_forTesting, 'class')\n",
    "y_categories = datasetCategoriesToNums(y_categories, 'spam')\n",
    "X_train, X_test, y_train, y_test = trainTestSplit(X_vectors, y_categories, 0.2, 25)\n",
    "instanceSampleRatio = 0.1\n",
    "featureSampleRatio = 0.5\n",
    "numModels = 5\n",
    "classification_PyClass = DecisionStump\n",
    "baggedModels =  baggingFit(X_train, y_train, instanceSampleRatio, featureSampleRatio, classification_PyClass, numModels)\n",
    "yHat = baggingPredict(X_test, baggedModels)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "allValidVals = lambda arrValues,validVals: False not in (val in validVals for val in arrValues) \n",
    "sameIndexes = lambda obj1,obj2: False not in (obj1.index.tolist()[n] == obj2.index.tolist()[n] for n in range(len(obj1.index))) \n",
    "innerElementTupple = lambda arrValues: False not in (isinstance(elem,tuple) for elem in arrValues)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "\n",
    "print (\"check basic 'getPrecision' output validation ...\")\n",
    "precision = getPrecision(yHat,y_test)\n",
    "assert precision is not None, 'precision not initialized'\n",
    "assert precision>0, 'precision should not be 0'\n",
    "assert precision<=1, 'precision should not be more than 1 (=100%)'\n",
    "assert precision>0.7, 'precision should not be >0.7 (more than 70%)'\n",
    "print ('pricision=%r' %(precision))\n",
    "print (\"----> The 'getPrecision' test passed successfully :-) \\n\")\n",
    "print ('\\nAdditional Tests might be executed on our side')\n",
    "\n",
    "print ('\\n----------------------')\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "if 'datasets' in sys.modules:\n",
    "    del (datasets)\n",
    "if 'train_test_split' in sys.modules:\n",
    "    del (train_test_split)\n",
    "if 'DecisionTreeClassifier' in sys.modules:\n",
    "    del (DecisionTreeClassifier)\n",
    "sys_modules = list(sys.modules.keys())\n",
    "for mdl in sys_modules:\n",
    "    if mdl.startswith('sklearn.'):\n",
    "        del(sys.modules[mdl]) \n",
    "del (sklearn)\n",
    "if 'sklearn' in sys.modules:\n",
    "    del (sys.modules['sklearn'])\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "dataset_forTesting = None\n",
    "X_vectors = None\n",
    "y_categories = None\n",
    "X_train = None\n",
    "X_test = None\n",
    "y_train = None\n",
    "y_test = None\n",
    "y_hat = None\n",
    "yHat = None\n",
    "\n",
    "instanceSampleRatio = None\n",
    "featureSampleRatio = None\n",
    "numModels = None\n",
    "classification_PyClass = None\n",
    "baggedModels = None\n",
    "\n",
    "nExamples = None\n",
    "y_hat_arr = None\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 5 - step 3 - evaluate recall     ----> Student's implementation - total 1 points\n",
    "<img src=\"./images/confusion_matrix-precision-recall.jpg\" alt=\"confusion_matrix-precision-recall\" width=\"300\" align='center'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "61a534760b431f9a711978e63a08aee9",
     "grade": false,
     "grade_id": "recall",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 5\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: getRecall\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# The following is expected:\n",
    "# --- the method needs to return the recall for class 1 (spam in out dataset)\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - y_hat -  a series of containing all predicted class values per test instance\n",
    "# - y_test - a series of containing all class values per test instance\n",
    "# ------------\n",
    "# return value:\n",
    "# - recall value\n",
    "# ---------------------\n",
    "# --- General notes:\n",
    "# Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "# In the line following the '# YOUR CODE HERE' line, add your code\n",
    "# ---------------------\n",
    "# --- Additional notes:\n",
    "# - You must use the parameters you've got. \n",
    "# - Do NOT define the parameters in the method.\n",
    "# --------------------------------------------------------\n",
    "\n",
    "def getRecall(y_hat,y_test):\n",
    "    # note that you could use getConfusionMatrix(y_hat,y_test) to make it simpler\n",
    "    # YOUR CODE HERE\n",
    "    TN,FP,FN,TP = getConfusionMatrix(y_hat,y_test)\n",
    "    result = TP / (FN + TP)\n",
    "    return result\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote.\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a49bb5f249f097904727a5243c46e74",
     "grade": true,
     "grade_id": "recall-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check basic 'getRecall' output validation ...\n",
      "recall=0.7701149425287356\n",
      "----> The 'getRecall' test passed successfully :-) \n",
      "\n",
      "\n",
      "Additional Tests might be executed on our side\n",
      "\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Important Notes:\n",
    "# - This test cell MUST NOT raise any exception\n",
    "# - It must pass all tests to get the point ----- #\n",
    "# - Do NOT change or delete this cell\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 1\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test of:\n",
    "### --- Graded tests for the 'getRecall' method \n",
    "# Important Note: additional test might also be taken from our side.\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Temporary imports:\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# --------\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetCsvFileName = folderName + os.sep + 'spam_notSpam.csv'\n",
    "# --------------------- \n",
    "dataset_forTesting = loadDataset(datasetCsvFileName)\n",
    "X_vectors, y_categories = separateTo_X_and_y(dataset_forTesting, 'class')\n",
    "y_categories = datasetCategoriesToNums(y_categories, 'spam')\n",
    "X_train, X_test, y_train, y_test = trainTestSplit(X_vectors, y_categories, 0.2, 25)\n",
    "instanceSampleRatio = 0.1\n",
    "featureSampleRatio = 0.5\n",
    "numModels = 10\n",
    "classification_PyClass = DecisionStump\n",
    "baggedModels =  baggingFit(X_train, y_train, instanceSampleRatio, featureSampleRatio, classification_PyClass, numModels)\n",
    "yHat = baggingPredict(X_test, baggedModels)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "allValidVals = lambda arrValues,validVals: False not in (val in validVals for val in arrValues) \n",
    "sameIndexes = lambda obj1,obj2: False not in (obj1.index.tolist()[n] == obj2.index.tolist()[n] for n in range(len(obj1.index))) \n",
    "innerElementTupple = lambda arrValues: False not in (isinstance(elem,tuple) for elem in arrValues)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "\n",
    "print (\"check basic 'getRecall' output validation ...\")\n",
    "recall = getRecall(yHat,y_test)\n",
    "assert recall is not None, 'precision not initialized'\n",
    "assert recall>0, 'recall should not be 0'\n",
    "assert recall<=1, 'recall should not be more than 1 (=100%)'\n",
    "assert recall>0.3, 'recall should not be >0.5 (more than 50%)'\n",
    "print ('recall=%r' %(recall))\n",
    "print (\"----> The 'getRecall' test passed successfully :-) \\n\")\n",
    "print ('\\nAdditional Tests might be executed on our side')\n",
    "\n",
    "print ('\\n----------------------')\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "if 'datasets' in sys.modules:\n",
    "    del (datasets)\n",
    "if 'train_test_split' in sys.modules:\n",
    "    del (train_test_split)\n",
    "if 'DecisionTreeClassifier' in sys.modules:\n",
    "    del (DecisionTreeClassifier)\n",
    "sys_modules = list(sys.modules.keys())\n",
    "for mdl in sys_modules:\n",
    "    if mdl.startswith('sklearn.'):\n",
    "        del(sys.modules[mdl]) \n",
    "del (sklearn)\n",
    "if 'sklearn' in sys.modules:\n",
    "    del (sys.modules['sklearn'])\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "dataset_forTesting = None\n",
    "X_vectors = None\n",
    "y_categories = None\n",
    "X_train = None\n",
    "X_test = None\n",
    "y_train = None\n",
    "y_test = None\n",
    "y_hat = None\n",
    "yHat = None\n",
    "\n",
    "instanceSampleRatio = None\n",
    "featureSampleRatio = None\n",
    "numModels = None\n",
    "classification_PyClass = None\n",
    "baggedModels = None\n",
    "\n",
    "nExamples = None\n",
    "y_hat_arr = None\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 6 - Bonus Question - maximum possible points: 5\n",
    "The following cells perform the following:\n",
    "* step 1 - evaluate accuracy ----> run only\n",
    "* step 2 - split the data-set to train-set, validation-set and test-set ----> run only\n",
    "* step 3 - bagging hyperparameters tuning ----> Student's implementation - total 5 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 6 - step 1 - evaluate accuracy   ----> run only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c58069385536de5ade9b7c83b03d0456",
     "grade": false,
     "grade_id": "accuracy",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.760043431053203\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# NO IMPLEMENTAION - DO NO CHANGE\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# methos: getConfusionMatrix\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# What does the method do?\n",
    "# --- computes the accuracy of the classifier\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - y_hat -  a series of containing all predicted class values per test instance\n",
    "# - y_test - a series of containing all class values per test instance\n",
    "# ------------\n",
    "# return value:\n",
    "# - accuracy value\n",
    "# --------------------- \n",
    "def getAccuracy(y_hat,y_test):\n",
    "    correct = float(len([1 for ind in range(len(y_test)) if y_test.iloc[ind]==y_hat.iloc[ind]]))\n",
    "    return correct/float(len(y_test))\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Temporary imports:\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# --------\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetCsvFileName = folderName + os.sep + 'spam_notSpam.csv'\n",
    "# --------------------- \n",
    "dataset_forTesting = loadDataset(datasetCsvFileName)\n",
    "X_vectors, y_categories = separateTo_X_and_y(dataset_forTesting, 'class')\n",
    "y_categories = datasetCategoriesToNums(y_categories, 'spam')\n",
    "X_train, X_test, y_train, y_test = trainTestSplit(X_vectors, y_categories, 0.2, 11)\n",
    "instanceSampleRatio = 0.1\n",
    "featureSampleRatio = 0.5\n",
    "numModels = 5\n",
    "classification_PyClass = DecisionStump\n",
    "baggedModels =  baggingFit(X_train, y_train, instanceSampleRatio, featureSampleRatio, classification_PyClass, numModels)\n",
    "y_hat = baggingPredict(X_test, baggedModels)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "accuracy = getAccuracy(y_hat,y_test)\n",
    "print ('accuracy: %r' %(accuracy))\n",
    "# --------------------------------------------------------\n",
    "if 'datasets' in sys.modules:\n",
    "    del (datasets)\n",
    "if 'train_test_split' in sys.modules:\n",
    "    del (train_test_split)\n",
    "if 'DecisionTreeClassifier' in sys.modules:\n",
    "    del (DecisionTreeClassifier)\n",
    "sys_modules = list(sys.modules.keys())\n",
    "for mdl in sys_modules:\n",
    "    if mdl.startswith('sklearn.'):\n",
    "        del(sys.modules[mdl]) \n",
    "del (sklearn)\n",
    "if 'sklearn' in sys.modules:\n",
    "    del (sys.modules['sklearn'])\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "dataset_forTesting = None\n",
    "X_vectors = None\n",
    "y_categories = None\n",
    "X_train = None\n",
    "X_test = None\n",
    "y_train = None\n",
    "y_test = None\n",
    "\n",
    "yHat = None\n",
    "\n",
    "instanceSampleRatio = None\n",
    "featureSampleRatio = None\n",
    "numModels = None\n",
    "classification_PyClass = None\n",
    "baggedModels = None\n",
    "\n",
    "nExamples = None\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 6 - step 2 - split the data-set to train-set, validation-set and test-set ----> run only\n",
    "<img src=\"./images/train-validation-test-split.png\" alt=\"train-validation-test split\" width=\"300\" align='center'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "62be65e60243b0bd9827fb0437841beb",
     "grade": false,
     "grade_id": "train-validation-test-split",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information after train-test split:\n",
      "* The train-set includes 2760 instances and 2760 corresponding categories\n",
      "* The validation-set includes 920 instances and 920 corresponding categories\n",
      "* The test-set includes 921 instances and 921 corresponding categories\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# NO IMPLEMENTAION - DO NO CHANGE\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name1: trainValidationTestSplit\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# What does the method do?\n",
    "# --- the method split the input dataset into train and test. \n",
    "#     - It does so using the sklearn built in method\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - X_vectors - a dataframe containing all feature vectors. \n",
    "# - y_categories - a series of containing all class values per instance.\n",
    "# - test_size_ratio - a number (0<number<1) of the wanted ratio of the dataset out of the dataset \n",
    "# - rand_state - a number, in order to guarantee reproducible results \n",
    "# ------------\n",
    "# return values (comma separated):\n",
    "# - X_train -  a dataframe containing all feature vectors of the train set\n",
    "# - X_test -  a dataframe containing all feature vectors of the test set\n",
    "# - y_train - a series of containing all class values per train instance\n",
    "# - y_test - a series of containing all class values per test instance\n",
    "# --------------------- \n",
    "def trainValidationTestSplit(X_vectors, y_categories, validation_or_test_size_ratio, rand_state):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_vectors, y_categories, test_size=validation_or_test_size_ratio, random_state=rand_state)\n",
    "    validationRatio = validation_or_test_size_ratio / (1-validation_or_test_size_ratio)\n",
    "    X_train, X_validation, y_train, y_validation =  train_test_split(X_train, y_train, test_size=validationRatio, random_state=rand_state)\n",
    "    return X_train, X_validation, X_test, y_train, y_validation, y_test  \n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Temporary imports:\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "# --------\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetCsvFileName = folderName + os.sep + 'spam_notSpam.csv'\n",
    "# --------------------- \n",
    "dataset_forTesting = loadDataset(datasetCsvFileName)\n",
    "X_vectors, y_categories = separateTo_X_and_y(dataset_forTesting, 'class')\n",
    "y_categories = datasetCategoriesToNums(y_categories, 'spam')\n",
    "X_train, X_validation, X_test, y_train, y_validation, y_test =  trainValidationTestSplit(X_vectors, y_categories, 0.2, 43)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "if 'datasets' in sys.modules:\n",
    "    del (datasets)\n",
    "if 'train_test_split' in sys.modules:\n",
    "    del (train_test_split)\n",
    "sys_modules = list(sys.modules.keys())\n",
    "for mdl in sys_modules:\n",
    "    if mdl.startswith('sklearn.'):\n",
    "        del(sys.modules[mdl]) \n",
    "del (sklearn)\n",
    "if 'sklearn' in sys.modules:\n",
    "    del (sys.modules['sklearn'])\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# display train-test split information\n",
    "# --------------------------------------------------------\n",
    "print ('Information after train-test split:')\n",
    "print('* The train-set includes %d instances and %d corresponding categories' %(X_train.shape[0],y_train.shape[0]))\n",
    "print('* The validation-set includes %d instances and %d corresponding categories' %(X_validation.shape[0],y_validation.shape[0]))\n",
    "print('* The test-set includes %d instances and %d corresponding categories' %(X_test.shape[0],y_test.shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 6 - step 3 - bagging hyperparameters tuning (using grid search) ----> Student's implementation - total 5 points\n",
    "<img src=\"./images/grid_search.png\" alt=\"train-validation-test split\" width=\"100\" align='center'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6398c5857a174c6b4cb5b14abb8f01c5",
     "grade": false,
     "grade_id": "hyperparametes-tune",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 5\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: baggingFit\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# The following is expected:\n",
    "# --- the method chooses the best permutation of bagging model hyperparameters, using grid search\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - X_train - a dataframe containing all feature vectors of the train set\n",
    "# - y_train - a series of containing all class values per train instance\n",
    "# - instanceSampleRatio - the ratio of the sampeling out of training set, \n",
    "#                        * we will pass it on as a parameter, in order to sample instances.\n",
    "#                        - if instanceSampleRatio<=0, no instance bootstrap is done, and we leave\n",
    "#                          the training instances with no change.\n",
    "# - featureSampleRatio - the ratio of the sampeling out of feature set,\n",
    "#                        * we will pass it on as a parameter, in order to sample features.\n",
    "#                        - if featureSampleRatio<=0, no feature bootstrap is done, and we leave\n",
    "#                          the features with no change.\n",
    "# - classificationAlgo_pyClass_Arr - an array of the python 'class' parameters of a classification algorithm to choose from,\n",
    "#                                For instance, the above [DecisionStump, NaiveBayes].\n",
    "#                                Note: passing the pyton class is similar to passing a method\n",
    "#                                      as a parameter.    \n",
    "# - numModels_Arr - an array of the options of the number of bagging models to train, for which we need to choose from\n",
    "#                   For instance: [3,5,10]\n",
    "# Note: the X_train, y_train parameters could be instance bootsraped, feature bootsraped or both\n",
    "# ------------\n",
    "# return values (comma seperated):\n",
    "# - allBaggedModels - an array of all trainedBaggedModels,\n",
    "# - best_baggedModels - array of the baggedModels ensembles (from baggeningFit), reaching the highest accuracy\n",
    "# - bestAccuracy - the highest accuracy (number) of all baggedModels ensemble\n",
    "# - best_classificationAlgo_pyClass - the classificationAlgo_pyClass (e.g. DecisionStump) of\n",
    "#                                     baggedModels ensemble with highest accuracy\n",
    "# - best_numModels - the num of 'bagged' Models (e.g. 5) of\n",
    "#                    baggedModels ensemble with highest accuracy\n",
    "# ---------------------\n",
    "# --- General notes:\n",
    "# Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "# In the line following the '# YOUR CODE HERE' line, add your code\n",
    "# ---------------------\n",
    "# --- Additional notes:\n",
    "# - You must use the parameters you've got. \n",
    "# - Do NOT define the parameters in the method.\n",
    "# --------------------------------------------------------\n",
    "def gridSearchBaggingModel(X_train, y_train, X_validation, y_validation, instanceSampleRatio, featureSampleRatio, classificationAlgo_pyClass_Arr, numModels_Arr):\n",
    "    # hint: for each permutation, use assistance functions:\n",
    "    #       - baggingFit, baggingPredict, getAccuracy \n",
    "    # YOUR CODE HERE\n",
    "    AllbaggedModels = []\n",
    "    bestAccuracy = 0.0\n",
    "    for numModels in numModels_Arr:\n",
    "        for classification_PyClass in classificationAlgo_pyClass_Arr:\n",
    "            baggedModels =  baggingFit(X_train, y_train, instanceSampleRatio, featureSampleRatio, classification_PyClass, numModels)\n",
    "            yHat = baggingPredict(X_validation, baggedModels)\n",
    "            currentAccuracy = getAccuracy(yHat,y_validation)\n",
    "            AllbaggedModels.append(baggedModels)\n",
    "            print(currentAccuracy)\n",
    "            if currentAccuracy >= bestAccuracy:\n",
    "                bestAccuracy = currentAccuracy\n",
    "                best_baggedModels = baggedModels\n",
    "                best_classificationAlgo_pyClass = classification_PyClass\n",
    "                best_numModels = numModels\n",
    "    print(bestAccuracy)\n",
    "    return AllbaggedModels, best_baggedModels, bestAccuracy, best_classificationAlgo_pyClass, best_numModels\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote.\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9dc255e185a039c097690ba2b38d2529",
     "grade": true,
     "grade_id": "hyperparametes-tune-test",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8119565217391305\n",
      "0.633695652173913\n",
      "0.775\n",
      "0.6195652173913043\n",
      "0.775\n",
      "0.6173913043478261\n",
      "0.8119565217391305\n",
      "check basic 'gridSearchBaggingModel' output validation ...\n",
      "----> The 'gridSearchBaggingModel' test passed successfully :-) \n",
      "\n",
      "\n",
      "Additional Tests might be executed on our side\n",
      "\n",
      "----------------------\n",
      "Best bagged Classification algo: 'DecisionStump', num of models: 5, accuracy: 0.8119565217391305\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Important Notes:\n",
    "# - This test cell MUST NOT raise any exception\n",
    "# - It must pass all tests to get the point ----- #\n",
    "# - Do NOT change or delete this cell\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 5\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test of:\n",
    "### --- Graded tests for the 'getRecall' method \n",
    "# Important Note: additional test might also be taken from our side.\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Temporary imports:\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# --------\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetCsvFileName = folderName + os.sep + 'spam_notSpam.csv'\n",
    "# --------------------- \n",
    "dataset_forTesting = loadDataset(datasetCsvFileName)\n",
    "X_vectors, y_categories = separateTo_X_and_y(dataset_forTesting, 'class')\n",
    "y_categories = datasetCategoriesToNums(y_categories, 'spam')\n",
    "X_train, X_validation, X_test, y_train, y_validation, y_test =  trainValidationTestSplit(X_vectors, y_categories, 0.2, 19)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "allValidVals = lambda arrValues,validVals: False not in (val in validVals for val in arrValues) \n",
    "sameIndexes = lambda obj1,obj2: False not in (obj1.index.tolist()[n] == obj2.index.tolist()[n] for n in range(len(obj1.index))) \n",
    "innerElementTupple = lambda arrValues: False not in (isinstance(elem,tuple) for elem in arrValues)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "instanceSampleRatio = 0.1\n",
    "featureSampleRatio = 0.5\n",
    "numModels_Arr = [5,10,40]\n",
    "classificationAlgo_pyClass_Arr = [DecisionStump,GaussianNB]\n",
    "allBaggedModels,best_baggedModels,bestAccuracy, best_classificationAlgo_pyClass,best_numOfModels = gridSearchBaggingModel(\n",
    "                        X_train, y_train, X_validation, y_validation, instanceSampleRatio, featureSampleRatio, \n",
    "                                                         classificationAlgo_pyClass_Arr, numModels_Arr)\n",
    "\n",
    "print (\"check basic 'gridSearchBaggingModel' output validation ...\")\n",
    "assert allBaggedModels is not None, 'allBaggedModels not initialized'\n",
    "assert best_baggedModels is not None, 'best_baggedModels not initialized'\n",
    "assert bestAccuracy is not None, 'bestAccuracy not initialized'\n",
    "assert best_classificationAlgo_pyClass is not None, 'best_classificationAlgo_pyClass not initialized'\n",
    "assert best_numOfModels is not None, 'best_numOfModels not initialized'\n",
    "assert isinstance(allBaggedModels, list), 'allBaggedModels object is not a list'\n",
    "assert isinstance(best_baggedModels, list), 'best_baggedModels object is not a list'\n",
    "assert bestAccuracy>0, 'bestAccuracy should not be 0'\n",
    "assert bestAccuracy<=1, 'bestAccuracy should not be more than 1 (=100%)'\n",
    "assert bestAccuracy>0.6, 'bestAccuracy should not be >0.6 (more than 60%)'\n",
    "assert None not in allBaggedModels, 'allBaggedModels should not include None elements'\n",
    "assert None not in best_baggedModels, 'best_baggedModels should not include None elements'\n",
    "\n",
    "print (\"----> The 'gridSearchBaggingModel' test passed successfully :-) \\n\")\n",
    "print ('\\nAdditional Tests might be executed on our side')\n",
    "\n",
    "print ('\\n----------------------')\n",
    "print ('Best bagged Classification algo: %r, num of models: %r, accuracy: %r' %(best_classificationAlgo_pyClass.__name__,best_numOfModels,bestAccuracy))\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "if 'datasets' in sys.modules:\n",
    "    del (datasets)\n",
    "if 'train_test_split' in sys.modules:\n",
    "    del (train_test_split)\n",
    "if 'DecisionTreeClassifier' in sys.modules:\n",
    "    del (DecisionTreeClassifier)\n",
    "sys_modules = list(sys.modules.keys())\n",
    "for mdl in sys_modules:\n",
    "    if mdl.startswith('sklearn.'):\n",
    "        del(sys.modules[mdl]) \n",
    "del (sklearn)\n",
    "if 'sklearn' in sys.modules:\n",
    "    del (sys.modules['sklearn'])\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "dataset_forTesting = None\n",
    "X_vectors = None\n",
    "y_categories = None\n",
    "X_train = None\n",
    "X_test = None\n",
    "y_train = None\n",
    "y_test = None\n",
    "y_hat = None\n",
    "yHat = None\n",
    "\n",
    "instanceSampleRatio = None\n",
    "featureSampleRatio = None\n",
    "numModels = None\n",
    "classification_PyClass = None\n",
    "baggedModels = None\n",
    "\n",
    "nExamples = None\n",
    "y_hat_arr = None\n",
    "# --------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
